{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Introduction: \n",
    "\n",
    "Understanding what a model does not know is a critical part of many machine learning systems. Unfortunately, today’s deep learning algorithms are usually unable to understand their uncertainty. These models are often taken blindly and assumed to be accurate, which is not always the case. For example, in two recent situations this has had disastrous consequences.\n",
    "\n",
    "Hiểu những gì mà model không biết là 1 phần cực kỳ quan trọng trong các hệ thống machine learning. Thật không may, hầu hết các thuật toán deep learning hiện tại thường không hiểu về sự không chắc chắn. Các model thường bị \"mù\" và được cho là \"đúng\". Ví dụ:\n",
    "\n",
    "- Năm 2015, một ứng dụng nhận dạng ảnh nhận dạng 2 người da màu là \"gorillas\", gây ra những tranh cãi về phân biệt chủng tộc.\n",
    "- Năm 2016, hệ thống hỗ trợ lái của xe ô tô Tesla gây ra một vụ tai nạn chết người. Nguyên nhân được xác định do hệ thống không nhận dạng được xe tải do có đốm sáng rực.\n",
    "\n",
    "Và còn rất nhiều câu chuyện khác. Bản thân chính model cần phải biết được những giới hạn của nó, nhờ đó tránh được những sai sót nguy hiểm. \n",
    "\n",
    "Ta thấy rõ ràng rằng tính không chắn chắn là điều model cần hiểu. Nhưng tại sao chưa có ai làm điều đó."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
